\chapter{Linear preferential trees} 
% LTeX: language=de-DE
%Das Kapitel beschreibt den Aufbau von \text{linear preferential trees} und wie diese zu Split Bäume 
In diesem Kapitel werden \textit{general preferential trees} eingeführt und die Einbettung von diesen in Devroyes \textit{Split} Bäume besprochen. Wir beginnen mit der Konstruktion von den jeweiligen Bäumen.
\\
\\
\textbf{\fontsize{14}{18}\selectfont Konstruktion von general preferential trees}\\
Der Aufbau von \textit{general preferential attachment trees} folgt im Wesentlichen dem Aufbau von \textit{random recursive Trees}. Wobei in \textit{Random recursive Trees} Knoten aufeinanderfolgend, mit uniformer Wahrscheinlichkeit als Kind von bereits existierenden Knoten angefügt werden, ist das Anknüpfen von Knoten von \textit{general preferential attachment trees} noch abhängig vom Ausgangsgrad von den existierenden Knoten. Präziser formuliert, wird der Vaterknoten $v$ von einem neuen Knoten, proportional zu $w_{d(v)}$ ausgesucht, wobei $d(v)$ der Ausgangsgrad vom Knoten $v$ ist, und $w_1, w_2...$ eine Folge von Gewichten ist. Der Fall $w_i = 1, \forall i \in \mathbb{N}$, führt somit genau auf den Fall von \textit{random recursive trees} zurück. In dieser Ausarbeitung werden die Gewichte von der Form 
\[
w_k = \chi k + \rho \hspace{5pt}, \chi \in \mathbb{R}\hspace{5pt} \rho > 0
\]
betrachtet, woher der Name \textit{linear preferential attachment trees} auch stammt. Da der Vaterknoten lediglich proportional zu der Folge von Gewichten ausgesucht wird, ändert die Skalierung der Folge nicht die Generierung der Baumstruktur, also beschränken wir die Betrachtung von den Gewichten auf 3 Spezialfälle:
\begin{enumerate}
    \item $\chi = 1$ ist der Fall vom \textit{general plane oriented recursive trees} \cite{panholzer2007level} 
    \item $\chi = 0$ ist der Fall vom \textit{random recursive trees}
    \item $\chi = -1$ ist der Fall von \textit{m-ary increasing trees}
\end{enumerate}
\begin{theorem}
\cite[Lemma 3.1]{janson2019random}
\label{Gewichte Satz}
   Mit den linearen Gewichten $w_k = \chi k + p $, hat ein Baum $T$ mit $m$ Knoten ein Gesamtgewicht $w(T) = (m-1)\chi + m\rho = m(\chi + \rho) - \chi$.
\end{theorem}
\begin{proof}
    Seien $d_1...d_m$ die Ausgangsgrade der jeweiligen Knoten im Baum. Dann ist die Summe der Ausgangsgrade, $\sum_{i=1}^{m}d_i = m-1$ und somit:
    \[
     w(T) = \sum_{i=1}^{m}w_i = \sum_{i=1}^{m} (\chi d_i + \rho) = m \rho + \chi \sum_{i = 1}^{m} d_i = m(\chi + \rho) - \chi.
    \]
\end{proof}
\begin{Definition}
    Falls $T$ ein verwurzelter Baum ist, und $v$ ein Knoten in $T$, so bezeichnen wir mit $T^v$ den Teilbaum von $T$ mit Wurzel $v$. Ein \textit{principal Subtree} $T^v$ von $T$ ist ein Teilbaum wo $v$ ein Kind von der Wurzel von $T$ ist.
\end{Definition}
\begin{theorem} \cite[Theorem 3.2]{janson2019random}
    \label{linpreft Grenzwert}
    Sei $(T_n)_1^\infty =(T_n^{\chi,\rho})_1^\infty = $ eine Folge von \linpreft, mit den Kindern von der Wurzel in der Reihenfolge ihres Erscheinens beschriftet. Sei $N_j(n) := |T^j_n|$, die Größe des j-ten \PsubT von $T_n$. Dann gilt 
    \[ 
        \forall j \geq 1  \hspace{6pt} \frac{N_j(n)}{n}  \rightarrow P_j \hspace{6pt} \text{für} \hspace{6pt} n \rightarrow \infty \hspace{6pt} \text{P-f.s.}.
  \]
Wobei die Zufallsvariablen  $P_j$ Verteilung $GEM(\frac{\chi}{\chi+\rho},{\frac{\rho}{\chi+\rho}})$ haben. \textcolor{red}{add case 0} 
\end{theorem}
\begin{proof}
    Da wir im Allgemeinen $\chi + \rho > 0 $ annehmen dürfen, und da die Multiplikation von allen $w_k$ mit einer Konstante nicht den Baum ändert, können wir o.B.d.A   $\chi + \rho = 1 $ annehmen. Das Argument folgt nun durch Übersetzung von \PsubT zu Zyklen in Permutationen und eine Bijektion zwischen \linpreft und Permutationen. Wir beginnen mit der Bijektion. \\
    Dafür beschriften wir die Knoten sukzessiv, beginnend mit der Wurzel als 0, nach der Reihenfolge vom Hinzufügen zum Baum (der $i$-ter Knoten der hinzugefügt wird, wird mit $i-1$ beschriftet). Die Wurzel, die mit 0 beschriftet wird, wird identifiziert mit der leeren Permutation und der Zweite Knoten, welcher mit 1 beschriftet wird, wird mit dem Zyklus $(1)$ identifiziert. Wir identifizieren nun unsere Bäume mit Permutationen induktiv, nach folgenden zwei Regeln:
    \begin{enumerate}
        \item Falls der Knoten mit Beschriftung $i$ an die Wurzel angehängt wird, so fügen wir zur bestehenden Zyklus-Dekomposition, die Fixpunkt-Permutation $(i)$ hinzu.
        \item Falls der Knoten mit Beschriftung $i$ an ein anderen Knoten mit Beschriftung $j$, $j \neq 0$ angehängt wird, so fügen wir in den Zyklus $C$, welcher $j$ enthält, $i$ direkt nach $j$ hinzu. Bedeutet also, falls im ursprünglichen Zyklus $j \rightarrow k$ abgebildet wurde, im nächsten Schritt $j \rightarrow i \rightarrow k$ abgebildet wird.
    \end{enumerate}
Es ist einfach zu zeigen, dass diese Abbildung von Bäumen zu Permutation, welche durch diese Konstruktion entsteht, bijektiv ist und somit können wir die Theorie der \textit{austauschbaren Partitionen} anwenden, insbesondere also Satz \ref{Main theorem CRP}. Dafür betrachten wir die bedingten Wahrscheinlichkeiten, dass der $n+1$-Knoten an principal Subtree $i$ angefügt wird, gegeben er enthält bereits $n_i$ Knoten. Nach Lemma \ref{Gewichte Satz}, hat dieser Teilbaum Gesamtgewicht $n_i(\chi + \rho) - \chi = n_i - \chi$ und der gesamte Baum Gewicht $m-\chi$. Die bedingten Wahrscheinlichkeiten entsprechen also denen in der Konstruktion von einem $(\chi,\rho)$ \textit{Chinese Restaurant Process} und die Aussage folgt direkt aus Satz \ref{Main theorem CRP}.
\end{proof}
\begin{Bemerkung}
    Satz \ref{linpreft Grenzwert} wird eine zentrale Rolle bei der Bestimmung des \textit{Split Vektors} in der Einbettung von \textit{linear preferential attachment trees} in Devroyes Split Bäume spielen. Wir führen zuerst den Begriff und die Konstruktion der Split Bäume ein und kommen dann schließlich zu dieser Einbettung.  
\end{Bemerkung}
\textbf{\fontsize{14}{18}\selectfont Konstruktion von Split Bäumen}\\
Sei $b \geq 2$ fest und $\mathcal{P} = (P_i)_{1 \leq i \leq b}$ ein zufälliger Wahrscheinlichkeitsvektor, also $P_i \geq 0$ und $\sum_{i=1}^{b}P_i = 1$. Sei $\mathcal{T}_b$ der unendliche Wurzelbaum, in dem jeder Knoten $b$ Kinder hat, beschriftet mit $1,...,b$. Wir geben jedem Knoten $v \in \mathcal{T}_b$ eine unabhängige Kopie von $\mathcal{P}$, die mit $\mathcal{P}^{(v)}$ bezeichnet wird. Jeder Knoten $v \in T_b$ kann maximal einen Knoten enthalten und falls dieser einen enthält, so nennen wir den Knoten \textit{voll}. Anfangs sind die Knoten leer und Bälle, beginnend mit der Wurzel, befüllen die Knoten nach folgenden zwei Regeln.
\begin{enumerate}
    \item Ein Ball, der an einem leeren Knoten ankommt, bleibt dort. Dieser Knoten ist dann \textit{voll}.
    \item Ein Ball, der an einem \textit{vollen} Knoten $v$ ankommt, bewegt sich weiter an die Kinder von $v$. Das Kind wird zufällig ausgewählt, wobei Kind $i$ mit Wahrscheinlichkeit $P_i^{(v)}$ ausgesucht wird.
\end{enumerate}
Der zufällige Split Baum $T_n = T_n^{\mathcal{P}}$ ist nun der Baum der entsteht, wenn nur die Knoten betrachtet werden, welche die ersten $n$ Bälle enthalten.
\begin{Bemerkung}
    Die hier vorgeführte Konstruktion ist nur eine Teilmenge von der allgemeineren Struktur von Devroyes Split Bäumen. In der Notation von Devroye \cite{devroye1998universal}, ist diese Teilmenge durch die Parameter $(s_0,s_1,s) = (1,0,1)$ festgelegt. Im weiteren Verlauf ist bei Bezugnahmen auf Split-Bäume stets dieser Spezialfall gemeint.
\end{Bemerkung}

Mit dieser Vorarbeit können wir nun die \textit{linear preferential attachment trees} in die Split Bäume einbetten, indem wir auch Split Bäume mit $b = \infty$ zulassen.
\begin{theorem}
    \label{main theorem paper}
    Seien $(\chi,\rho)$ Parameter, welche die Voraussetzungen vom \textit{Chinese Restaurant Process} erfüllen und $\chi + \rho > 0$. Dann, falls die Bäume als ungeordnete Bäume betrachtet werden, hat der \textit{linear preferential attachment tree} $T_n^{\chi,\rho}$ für alle $n \in \mathbb{N}$ die selbe Verteilung wie der zufällige Split Baum $T^\mathcal{P}_n$ mit $b = \infty$ und 
    \[ 
    \mathcal{P} \sim PD(\frac{\chi}{\chi + \rho}, \frac{\rho}{\chi + \rho})
    \] 
\end{theorem}
\begin{proof}
    Die Hauptidee hinter der Beweis liegt darin, die Konstruktion der \textit{linear preferential attachment trees} in einer rekursiven Form aufzufassen und dann die Verteilung vom \textit{Split Vektor} $\mathcal{P}$ mithilfe von Satz \ref{Main theorem CRP} zu bestimmen.\\
    Nach Konstruktion der \textit{linear preferential attachment trees} wird ein neuer Knoten an einen bestehenden Knoten $u$ proportional zum Gewicht vom Knoten $w_{d(u)}$ angehängt. Die Wahrscheinlichkeit, dass ein Knoten an eine bestehende Gruppe von Knoten angehängt wird, ist daher proportional zur Summe der Gewichte dieser Gruppe. Dies erlaubt uns den Aufbau vom Baum rekursiv zu beschreiben. Dafür formulieren wir die Konstruktion vom \textit{linear preferential attachment tree} nach folgenden Regeln um.
    \begin{enumerate}
        \item Ein Ball, der an einem leeren Knoten ankommt, bleibt dort. Dieser Knoten ist dann \textit{voll}.
        \item Ein Ball, der an einem \textit{vollen} Knoten $v$ ankommt, bewegt sich weiter an die Kinder von $v$. Falls Knoten $v$ $d$ Kinder $v_1,v_2...v_d$ hat, so bewegt sich dieser an Kind $i$ mit Wahrscheinlichkeit $w(T^{v_i})/w(T^{v})$ für alle $i \in \{1...d\}$ und an ein neues Kind $d+1$ mit Wahrscheinlichkeit $(\chi d + \rho)/w(T^{v})$.
    \end{enumerate} 
    Wir beschriften die Bälle nach der Reihenfolge ihres Erscheinens beginnend mit der Wurzel als $0$ (d.h. der $i+1$-te Ball der zum Baum hinzugefügt wird, hat Beschriftung $i$). Seien weiter die Anzahl der Bälle im $j$-ten \textit{principal Subtree} von $T_n$ mit $n_j$ bezeichnet.
    Nach Satz \ref{Gewichte Satz} können wir die Wahrscheinlichkeiten von der zweiten Regel berechnen.
    \begin{align}
         \frac{w(T^{v_i})}{w(T^{v})} &= \frac{n_i(\chi + \rho) - \chi}{n(\chi+ \rho) - \chi} = \frac{n_i - \chi}{ n + \rho} \label{Gewicht 1}\\  
         \frac{\chi d + \rho}{w(T^{v})} &= \frac{\chi d + \rho}{ n + \rho} \label{Gewicht 2}.
    \end{align}
    Wobei hier, Analog zu Satz \ref{linpreft Grenzwert}, $\chi + \rho = 1$ angenommen wurde.  Falls man die \textit{Principal Subtrees} nun mit Tischen identifiziert, so sieht man direkt anhand \ref{Gewicht 1} und \ref{Gewicht 2}, dass diese 2 Regeln von der Wurzel aus gesehen einen $(\chi,\rho)$-\textit{Chinese Restaurant Process} widerspiegeln.\\
    Andererseits, besagt Satz \ref{Kingmans representation}, dass jede austauschbare zufällige Partition die gleiche Verteilung hat, wie ein $(P^{\downarrow}_i)_{i \in \mathbb{N}}$-\textit{Paintbox Prozess}, wobei $P^{\downarrow}_i$ der P-f.s. Grenzwert von der normierten $i$-ten Blockgröße von der Partition ist. Da in unserem Fall die Blockgrößen die Größen der \textit{principal subtrees} sind, können auch Split-Bäume mithilfe der Theorie der austauschbaren Partionen dargestellt werden. Dafür betrachten wir die Verteilung der Bälle in die \textit{principal Subtrees} nachdem die Wurzel mit einem Ball besetzt ist. Diese Verteilung ist Äquivalent zu einem $\mathcal{P}^{v} = (P_i^{\downarrow})_{i \in \mathbb{N}}$-Paintbox Prozess, falls man die Kinder der Knoten in einen Split Baum nach Reihenfolge ihres Erscheinens umbenennt. Nach Definition \ref{GEM und PD Verteilungen} und Satz \ref{Main theorem CRP} ist $(P^{\downarrow}_i)_{i \in \mathbb{N}} \sim PD(\chi,\rho)$ und die Behauptung ist gezeigt. 

\end{proof}
\begin{Bemerkung}
    \label{Bemerkung PD Verteilungen}
    In dieser Abwandlung der Konstruktion vom Split Baum kann der \textit{Split Vektor} beliebig permutiert werden, da die Knoten in Reihenfolge ihres Erscheinens neu benannt wurden. Das bedeutet, dass der Satz für jede Permutation von einer $PD(\chi,\rho)$ Verteilung auch gilt, insbesondere also auch für die $GEM(\chi,\rho)$ Verteilung (Siehe Definition \ref{GEM und PD Verteilungen}).
\end{Bemerkung}
In Devroyes Publikation \cite{devroye1998universal} spielt die Größen-verzerrte Version $W$ von $\mathcal{P}$ eine wichtige Rolle. Die Verteilung ist durch folgendes Sampling festgelegt.
\begin{enumerate}
    \item Gegeben $\mathcal{P} = (P_i)_{i \in \mathbb{N}}$, sei $I$ eine Zufallsvariable welche durch Verteilung $P(I=i) = P_i, \forall i \in \mathbb{N}$ definiert ist.
    \item $W:= P_I$ 
\end{enumerate}
oder in einer anderen Schreibweise
\[
    P(W = P_i| (P_i)_{i \in \mathbb{N}}) = P_i.
\]
In unserem Fall ist die explizite Berechnung der Verteilung von $W$ recht einfach.
\begin{theorem}
    \label{Verteilung W}
    Für den zufälligen Split Baum aus Satz \ref{main theorem paper}, ist $W \sim \beta(\rho,1)$.
\end{theorem} 
\begin{proof}
    Wir nutzen die Einbettung von \textit{linear preferential attachment trees} in die Split Bäume. Sei $I$ die Zufallsvariable welche die Beschriftung vom ersten erschienen Knoten übernimmt (bevor die Knoten umbenannt werden). Nach Voraussetzung, gilt 
    \[
    P(I=i|(P_i)_{i \in \mathbb{N}}) = P_i.  
    \] 
    Sei weiter $S_n$ die Anzahl der Knoten im ersten \textit{principal Subtree}. Bedingt auf $I=i$, gilt nach dem Gesetz der großen Zahlen, dass 
    \[
    \frac{S_n}{n} \rightarrow P_i \hspace{5pt} P-\textnormal{f.s.} \hspace{5pt} \textnormal{für } n \to \infty.
    \] 
    Daher folgt $\frac{S_n}{n} \rightarrow P_I = W$ P-f.s. für $n \to \infty$.\\
    Durch die Einbettung, kennen wir aber die relative Größe vom ersten \textit{principal Subtree} welcher durch Satz \ref{Main theorem CRP} durch $P_1 = W_1 \sim \beta(1-\chi,\chi + \rho) = \beta(\chi, 1)$ gegeben ist. Es folgt, dass $W \sim \beta(\chi,1)$ und die Behauptung ist gezeigt.
\end{proof}